---
title: "Pacman Multiagent"
---

Tato část dokumentuje řešení sady úloh zaměřených na inteligentní agenty v prostředí Pacmana. Cílem bylo implementovat a otestovat algoritmy prohledávání stavového prostoru v reálném čase.

::: {.callout-note}
Všechny implementace splňují požadavky autograderu na **100 %** (plný počet bodů).
:::

## Reflex Agent
Prvním krokem byl návrh reflexivního agenta, který se rozhoduje pouze na základě aktuálního stavu, bez prohledávání do hloubky.

### Klíčové principy
- **Jídlo**: Agent je motivován převrácenou vzdáleností k nejbližšímu jídlu (čím blíže, tím lépe).
- **Duchové**: Pokud je duch příliš blízko (vzdálenost < 2) a není ve stavu "scared", agent dostává extrémní penalizaci.
- **Scared Ghosts**: Pokud je duch zranitelný, agent je motivován k jeho snědení (ale s menší prioritou než přežití).

## Minimax
Implementace algoritmu Minimax umožňuje agentovi předvídat tahy soupeřů (duchů) za předpokladu, že hrají optimálně (snaží se minimalizovat Pacmanovo skóre).

### Implementace
Algoritmus je implementován rekurzivně. Pacman (MAX) maximalizuje hodnotící funkci, zatímco duchové (MIN) ji minimalizují.

```python
# Ukázka logiky rozhodování (pseudokód)
def get_action(state, depth, agent_index):
    if terminal(state) or depth == 0:
        return evaluate(state)
        
    if agent_index == PACMAN:
        return max(get_action(next_state, depth, next_agent) for next_state in successors) # <1>
    else:
        return min(get_action(next_state, depth, next_agent) for next_state in successors) # <2>
```
1. Pacman hledá tah s nejvyšším ohodnocením.
2. Duchové hledají tah, který Pacmanovi nejvíce uškodí.

## Alpha-Beta Pruning
Pro zefektivnění prohledávání byla implementována metoda Alpha-Beta prořezávání. Ta umožňuje ignorovat větve stromu, které nemohou ovlivnit finální rozhodnutí.

- **Alpha**: Nejlepší hodnota, kterou může MAX (Pacman) zaručit.
- **Beta**: Nejlepší hodnota, kterou může MIN (Duch) zaručit.

Pokud v uzlu MIN nalezneme hodnotu menší než Alpha, víme, že MAX do tohoto uzlu nikdy nevstoupí, a můžeme prohledávání ukončit (pruning).

::: {.callout-tip}
Tato optimalizace umožnila prohledávat do větší hloubky ve stejném čase, což vedlo k výrazně silnější hře agenta.
:::

:::

## Expectimax
Zatímco Minimax předpokládá optimálně hrajícího soupeře, **Expectimax** modeluje duchy jako agenty, kteří se rozhodují částečně náhodně (suboptimálně).

- **Pacman (MAX)**: Stále maximalizuje své skóre.
- **Duchové (CHANCE)**: Místo minimalizace počítáme **očekávanou hodnotu** (vážený průměr) všech možných tahů.
- **Předpoklad**: Duchové vybírají tahy z uniformní distribuce (náhodně).

$$ V(s) = \sum_{a \in Actions(s)} P(a) \times V(Successor(s, a)) $$

```python
# Ukázka logiky rozhodování (pseudokód)
if agent_index == PACMAN:
    return max(get_action(next_state, depth, next_agent) for next_state in successors)
else:
    # Duchové hrají náhodně (průměrná hodnota)
    return sum(get_action(next_state, depth, next_agent) for next_state in successors) / len(successors)
```

### Výhody přístupu
Tento přístup je v prostředí Pacmana často efektivnější než Minimax, protože duchové nehraji vždy perfektně. Expectimax se nesnaží "přežít za každou cenu" proti nejhoršímu scénáři (který nenastane), ale maximalizuje průměrný zisk. To vede k odvážnějšímu chování, kdy Pacman "riskuje" pro získání jídla, pokud je pravděpodobnost chycení nízká.

## Better Evaluation Function: "Thrill-Seeking" Agent
V poslední části projektu jsem navrhl vlastní hodnotící funkci (`betterEvaluationFunction`), která transformuje Pacmana z opatrného sběrače na agresivního lovce.

### 1. Řešení "Zeno's Paradox" (Oscilace)
Během vývoje jsem narazil na problém, kdy Pacman osciloval v blízkosti kapsle nebo jídla, ale nesnědl je. Příčinou bylo, že **odměna za blízkost** (např. `+50` bodů za vzdálenost 1) byla vyšší než okamžitý zisk z konzumace (který paradoxně tuto odměnu zrušil).

**Řešení:** Invertoval jsem logiku z odměn na **penalizace za existenci**.
- Každá existující tečka jídla: `-20` bodů.
- Každá existující kapsle: `-500` bodů.

Tímto způsobem je konzumace objektu (jeho odstranění ze seznamu) jediným způsobem, jak se zbavit masivní penalizace. To Pacmana matematicky nutí k akci a zabraňuje "čekání".

### 2. Operation Ghostbuster (Ambush Logic)
Agent implementuje speciální "kombo" logiku pro lov duchů. Pokud se duch nachází v blízkosti kapsle (vzdálenost < 5), agent to vyhodnotí jako příležitost k pasti:
- Penalizace za nesnědenou kapsli se drasticky zvýší (`-800` a strmější gradient).
- To vyvolá "paniku" v hodnotící funkci, která Pacmana donutí okamžitě sprintovat pro kapsli a následně zkonzumovat zranitelného ducha.

### 3. Agresivní lov (Strict Dominance)
Agent prioritizuje lov zranitelných duchů nad sběrem jídla. Matematická váha za snědení ducha (`+200`) je nastavena tak, aby striktně dominovala nad jakoukoli kombinací vzdálenosti k jídlu.
```python
if scaredTimer > 0:
    # Aggressive Chase
    ghost_score += 100.0 / (dist + 1)
else:
    # Active Avoidance
    if dist <= 1: return -999999.0
```

Tato kombinace strategií vede k agentovi, který nejen efektivně čistí bludiště, ale aktivně vyhledává a eliminuje hrozby v "Thrill-Seeking" stylu.

## Závěr "Warm-up" části
Tato sada úloh posloužila jako ověření základních principů adversariálního prohledávání. Získané znalosti (zejména o Alpha-Beta prořezávání a návrhu heuristik) byly následně aplikovány a výrazně rozšířeny v hlavní části práce - **Analýze Anglické dámy**.
